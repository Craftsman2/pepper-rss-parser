import requests
from bs4 import BeautifulSoup
from feedgen.feed import FeedGenerator
from datetime import datetime
import pytz
import re # –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫
import os # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å os –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ScraperAPI ---
API_KEY = os.environ.get("SCRAPERAPI_API_KEY") # <-- –í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ –≤–∞—à API-–∫–ª—é—á —Å ScraperAPI.com
SCRAPERAPI_URL = "http://api.scraperapi.com/"
TARGET_URL = "https://www.pepper.ru/new"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è ScraperAPI
scraperapi_params = {
    'api_key': API_KEY,
    'url': TARGET_URL,
    'country_code': 'ru',
    'render': 'true',
    'session_number': '123' # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏ (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ IP –Ω–∞ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏)
                            # –£–¥–∞–ª–∏—Ç–µ, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ –∏–ª–∏ –Ω–µ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏–∏
}

base_url = "https://www.pepper.ru"
entries = []
fg = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º fg –∫–∞–∫ None, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å NameError, –µ—Å–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ fg –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ

try:
    print(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ ScraperAPI –∫: {TARGET_URL}")
    # –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–æ 180 —Å–µ–∫—É–Ω–¥ (3 –º–∏–Ω—É—Ç—ã)
    response = requests.get(SCRAPERAPI_URL, params=scraperapi_params, timeout=180) 

    if response.status_code == 200:
        html_content = response.text
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ ScraperAPI. –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(html_content)}")

        # –ü–∞—Ä—Å–∏–Ω–≥ HTML —Å –ø–æ–º–æ—â—å—é BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')

        all_found_cards = []

        # --- –ü—É—Ç—å 2: deals-list -> article ---
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä deals-list
        deals_list_container = soup.find('div', class_='deals-list')
        if deals_list_container:
            print("‚úÖ 'deals-list' –Ω–∞–π–¥–µ–Ω.")
            # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã article –í–ù–£–¢–†–ò deals-list
            articles_in_deals_list = deals_list_container.find_all('article')
            if articles_in_deals_list:
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(articles_in_deals_list)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ 'article' –≤–Ω—É—Ç—Ä–∏ 'deals-list'.")
                all_found_cards.extend(articles_in_deals_list)
            else:
                print("‚ùå –≠–ª–µ–º–µ–Ω—Ç—ã 'article' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ 'deals-list'.")
        else:
            print("‚ùå 'deals-list' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º.")

        # –¢–µ–ø–µ—Ä—å offer_cards - —ç—Ç–æ all_found_cards. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, offer_cards –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º.
        offer_cards = all_found_cards
        if not offer_cards:
            print("‚ùå –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä 'deals-list' –∏–ª–∏ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã 'article' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º.")


        print("üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–∫–∏–¥–∫–∏:")

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ
        for i, card in enumerate(offer_cards): # –ò—Å–ø–æ–ª—å–∑—É–µ–º enumerate –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ "card" —É–∂–µ —Ç–µ–≥–æ–º <a> (–µ—Å–ª–∏ —ç—Ç–æ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞),
            # –∏–ª–∏ –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å <a> –≤–Ω—É—Ç—Ä–∏ –¥—Ä—É–≥–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ (swiper-slide, article)
            offer_link_tag = card.find('a', href=re.compile(r'^/deals/')) if card.name != 'a' else card
            
            if not offer_link_tag:
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ —Å–¥–µ–ª–∫—É

            href = offer_link_tag.get('href')
            title = offer_link_tag.get_text(strip=True)
            image_url = None

            # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ (card)
            img_tag = card.find('img', src=True)
            
            if img_tag:
                potential_image_url = img_tag['src']
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ URL "cdn"
                if potential_image_url and "cdn" in potential_image_url:
                    image_url = potential_image_url
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö URL
                    if image_url: # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ image_url –Ω–µ –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                        if image_url.startswith('//'):
                            image_url = 'https:' + image_url
                        elif image_url.startswith('/'):
                            image_url = base_url + image_url

            if title:
                full_link = base_url + href
                print(f"üìå {i+1}. –ù–∞–∑–≤–∞–Ω–∏–µ: {title}") # –í—ã–≤–æ–¥–∏–º –Ω–æ–º–µ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞
                print(f"üîó –°—Å—ã–ª–∫–∞:   {full_link}")
                if image_url:
                    print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
                print()

                entries.append({
                    'title': title,
                    'link': full_link,
                    'image': image_url,
                    'index': i + 1 # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –≤ –∑–∞–ø–∏—Å—å
                })

        # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∫–ª—é—á - —Å—Å—ã–ª–∫–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–π –∏ —Ç–æ–π –∂–µ —Å–¥–µ–ª–∫–∏)
        # –ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –∑–∞ —Å—á–µ—Ç –ª–æ–≥–∏–∫–∏ —Å ordered_unique_entries
        ordered_unique_entries = []
        seen_links = set()
        for entry in entries:
            if entry['link'] not in seen_links:
                ordered_unique_entries.append(entry)
                seen_links.add(entry['link'])
        
        # –¢–µ–ø–µ—Ä—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        unique_entries = ordered_unique_entries

        # RSS
        fg = FeedGenerator() # fg –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∑–¥–µ—Å—å
        fg.id(TARGET_URL)
        fg.title('–°–∫–∏–¥–∫–∏ —Å Pepper.ru')
        fg.link(href=TARGET_URL, rel='alternate')
        fg.description('–ù–æ–≤—ã–µ —Å–∫–∏–¥–∫–∏ —Å —Å–∞–π—Ç–∞ Pepper.ru')
        fg.language('ru')

        # –û–±—â–∞—è —Å–µ–∫—Ü–∏—è <image> –¥–ª—è –∫–∞–Ω–∞–ª–∞ RSS —É–¥–∞–ª–µ–Ω–∞

        timezone = pytz.timezone('Europe/Chisinau')

        # –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –¥–ª—è RSS-—Ñ–∏–¥–∞
        for entry in reversed(unique_entries): # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–¥–µ—Å—å: –∏—Å–ø–æ–ª—å–∑—É–µ–º reversed()
            fe = fg.add_entry()
            fe.id(entry['link'])
            fe.title(f"[{entry['index']}] {entry['title']}") # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–µ
            fe.link(href=entry['link'])
            fe.pubDate(timezone.localize(datetime.now()))

            # --- –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ (<item>) ---
            if entry['image']:
                # –í–∞—Ä–∏–∞–Ω—Ç 1: –î–æ–±–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ HTML –≤ –æ–ø–∏—Å–∞–Ω–∏–µ (—Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –∏ —à–∏—Ä–æ–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π)
                fe.description(f'<img src="{entry["image"]}" /><br/>{entry["title"]}')

                # –í–∞—Ä–∏–∞–Ω—Ç 2: –î–æ–±–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ enclosure (–±–æ–ª–µ–µ "–ø—Ä–∞–≤–∏–ª—å–Ω–æ" –¥–ª—è RSS)
                # –¢—Ä–µ–±—É–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è MIME-—Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'image/jpeg', 'image/png')
                # –∏ –µ–≥–æ –¥–ª–∏–Ω—ã. –ï—Å–ª–∏ —Ç–æ—á–Ω–∞—è –¥–ª–∏–Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 0 –∏–ª–∏ 1.
                image_type = None
                if entry['image'].endswith(('.jpg', '.jpeg')):
                    image_type = 'image/jpeg'
                elif entry['image'].endswith('.png'):
                    image_type = 'image/png'
                elif entry['image'].endswith('.gif'):
                    image_type = 'image/gif'
                
                if image_type:
                    fe.enclosure(url=entry['image'], length='0', type=image_type)
                else:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è enclosure: {entry['image']}")

        # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ RSS-—Ñ–∏–¥–∞ ---
        rss_file = 'pepper_feed.xml'
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if os.path.exists(rss_file):
            try:
                os.remove(rss_file)
                print(f"‚úÖ –ü—Ä–µ–¥—ã–¥—É—â–∏–π —Ñ–∞–π–ª {rss_file} —É–¥–∞–ª–µ–Ω.")
            except OSError as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {rss_file}: {e}")
        
        fg.rss_file(rss_file)
        print(f"\n‚úÖ RSS-—Ñ–∏–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {rss_file}")
    else:
        # –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –∫–æ–¥ –Ω–µ 200, —Ç–æ fg –Ω–µ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ —ç—Ç–æ–º –±–ª–æ–∫–µ
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ ScraperAPI. –°—Ç–∞—Ç—É—Å –∫–æ–¥: {response.status_code}")
        print(f"–¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞: {response.text[:500]}...")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è GitHub Actions
        raise Exception(f"–û—à–∏–±–∫–∞ ScraperAPI: {response.status_code}")

except requests.exceptions.RequestException as req_e:
    print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ HTTP-–∑–∞–ø—Ä–æ—Å–∞: {req_e}")
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è GitHub Actions
    raise Exception(f"–û—à–∏–±–∫–∞ HTTP-–∑–∞–ø—Ä–æ—Å–∞: {req_e}")
except Exception as e:
    print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è GitHub Actions
    raise Exception(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
