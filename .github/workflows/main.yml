name: Запуск парсера Pepper (ScraperAPI) и сохранение в Main

on:
  schedule:
    # Запускать каждый час
    - cron: '0 * * * *'
  workflow_dispatch: # Позволяет запускать вручную

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Клонировать репозиторий
      uses: actions/checkout@v4
      with:
        # Важно: необходимо получить токен для записи в репозиторий
        # По умолчанию checkout action использует токен, который может не иметь прав на push
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Настроить Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x' # Укажите нужную версию Python, например '3.9' или '3.10'

    - name: Установить зависимости
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 feedgen pytz

    - name: Запустить скрипт Python
      env:
        SCRAPERAPI_API_KEY: ${{ secrets.SCRAPERAPI_API_KEY }} # Передаем API-ключ как переменную окружения
      run: python pepper_parser.py

    - name: Настроить Git и зафиксировать изменения в main
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        # Проверяем, есть ли изменения в файле, чтобы избежать пустых коммитов
        git add pepper_feed.xml
        git diff-index --quiet HEAD || (git commit -m "Автоматическое обновление RSS-фида pepper_feed.xml [skip ci]" && git push)
        echo "Проверка завершена. Если файл изменился, он был закоммичен и отправлен."
